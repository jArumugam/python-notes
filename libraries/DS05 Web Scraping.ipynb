{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Source](https://github.com/jmportilla/Web-Scraping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this appendix lecture we'll go over how to scrape information from the web using Python. \n",
    "\n",
    "##### We'll go to a website, decide what information we want, see where and how it is stored, then scrape it and set it as a pandas DataFrame!\n",
    "\n",
    "#### Some things you should consider before web scraping a website:\n",
    "\n",
    "1.) You should check a site's terms and conditions before you scrape them. \n",
    "\n",
    "2.) Space out your requests so you don't overload the site's server, doing this could get you blocked.\n",
    "\n",
    "3.) Scrapers break after time - web pages change their layout all the time, you'll more than likely have to rewrite your code. \n",
    "\n",
    "4.) Web pages are usually inconsistent, more than likely you'll have to clean up the data after scraping it.\n",
    "\n",
    "5.) Every web page and situation is different, you'll have to spend time configuring your scraper.\n",
    "\n",
    "#### To learn more about HTML I suggest theses two resources:\n",
    "\n",
    "[W3School](http://www.w3schools.com/html/)\n",
    "\n",
    "[Codecademy](http://www.codecademy.com/tracks/web)\n",
    "\n",
    "\n",
    "#### There are three modules we'll need in addition to python are:\n",
    "\n",
    "1.) BeautifulSoup, which you can download by typing: *pip install beautifulsoup4* or *conda install beautifulsoup4* (for the Anaconda distrbution of Python) in your command prompt.\n",
    "\n",
    "2.) lxml , which you can download by typing: *pip install lxml* or *conda install lxml* (for the Anaconda distrbution of Python) in your command prompt.\n",
    "\n",
    "3.) requests,  which you can download by typing: *pip install requests* or *conda install requests* (for the Anaconda distrbution of Python) in your command prompt.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start with our imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import Series,DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our quick web scraping tutorial, we'll look at some legislative reports from the University of California Web Page. Feel free to experiment with other webpages, but remember to be cautious and respectful in what you scrape and how often you do it. Always check the legality of a web scraping job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Let's go ahead and set the url."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = 'http://www.ucop.edu/operating-budget/budgets-and-reports/legislative-reports/2013-14-legislative-session.html'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now let's go ahead and set up requests to grab content form the url, and set it as a Beautiful Soup object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Request content from web page\n",
    "result = requests.get(url)\n",
    "c = result.content\n",
    "\n",
    "# Set as Beautiful Soup Object\n",
    "soup = BeautifulSoup(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll use Beautiful Soup to search for the table we want to grab!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Go to the section of interest\n",
    "summary = soup.find(\"div\",{'class':'list-land','id':'content'})\n",
    "\n",
    "# Find the tables in the HTML\n",
    "tables = summary.find_all('table')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to use Beautiful Soup to find the table entries. A 'td' tag  defines a standard cell in an HTML table. The 'tr' tag defines a row in an HTML table.\n",
    "\n",
    "We'll parse through our tables object and try to find each cell using the findALL('td') method.\n",
    "\n",
    "There are tons of options to use with findALL in beautiful soup. You can read about them [here](http://www.crummy.com/software/BeautifulSoup/bs4/doc/#find-all)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 08/01/13 2013-14 (EDU 92495) Proposed Capital Outlay Projects (2013-14 only) (pdf) 2 09/01/13 2014-15  (EDU 92495) Proposed Capital Outlay Projects (pdf) 3 11/01/13 Utilization of Classroom and Teaching Laboratories (pdf) 4 11/01/13 Instruction and Research Space Summary & Analysis (pdf) 5 11/15/13 Statewide Energy Partnership Program (pdf) 6 11/30/13 2013-23 Capital Financial Plan (pdf) 7 11/30/13 Projects Savings Funded from Capital Outlay Bond Funds (pdf) 8 12/01/13 Streamlined Capital Projects Funded from Capital (pdf) 9 01/01/14 Annual General Obligation Bonds Accountability (pdf) 10 01/01/14 Small Business Utilization (pdf) 11 01/01/14 Institutional Financial Aid Programs - Preliminary report (pdf) 12 01/10/14 Summer Enrollment (pdf) 13 01/15/14 Contracting Out for Services at Newly Developed Facilities (pdf) 14 03/01/14 Performance Measures (pdf) 15 03/01/14 Entry Level Writing Requirement (pdf) 16 03/31/14 Annual Report on Student Financial Support (pdf) 17 04/01/14 Unique Statewide Pupil Identifier (pdf) 18 04/01/14 Riverside School of Medicine (pdf) 19 04/01/14 SAPEP Funds and Outcomes - N/A 20 05/15/14 Receipt and Use of Lottery Funds (pdf) 21 07/01/14 Cogeneration and Energy Consv Major Capital Projects (pdf) \n",
      "\n",
      "\n",
      " Future Reports \n",
      "24 12- Breast Cancer Research Fund 25 12-31-15 Cigarette and Tobacco Products Surtax Research Program 26 01-01-16 Best Value Program 27 01-01-16 California Subject Matter Programs 28 04-01-16 COSMOS Program Outcomes\n"
     ]
    }
   ],
   "source": [
    "# Set up empty data list\n",
    "data = []\n",
    "\n",
    "# Set rows as first indexed object in tables with a row\n",
    "rows = tables[0].findAll('tr')\n",
    "\n",
    "# now grab every HTML cell in every row\n",
    "for tr in rows:\n",
    "    cols = tr.findAll('td')\n",
    "    # Check to see if text is in the row\n",
    "    for td in cols:\n",
    "        text = td.find(text=True) \n",
    "        print text,\n",
    "        data.append(text)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what the data list looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'1',\n",
       " u'08/01/13',\n",
       " u'2013-14 (EDU 92495) Proposed Capital Outlay Projects (2013-14 only) (pdf)',\n",
       " u'2',\n",
       " u'09/01/13',\n",
       " u'2014-15\\xa0 (EDU 92495) Proposed Capital Outlay Projects (pdf)',\n",
       " u'3',\n",
       " u'11/01/13',\n",
       " u'Utilization of Classroom and Teaching Laboratories (pdf)',\n",
       " u'4',\n",
       " u'11/01/13',\n",
       " u'Instruction and Research Space Summary & Analysis (pdf)',\n",
       " u'5',\n",
       " u'11/15/13',\n",
       " u'Statewide Energy Partnership Program (pdf)',\n",
       " u'6',\n",
       " u'11/30/13',\n",
       " u'2013-23 Capital Financial Plan (pdf)',\n",
       " u'7',\n",
       " u'11/30/13',\n",
       " u'Projects Savings Funded from Capital Outlay Bond Funds (pdf)',\n",
       " u'8',\n",
       " u'12/01/13',\n",
       " u'Streamlined Capital Projects Funded from Capital (pdf)',\n",
       " u'9',\n",
       " u'01/01/14',\n",
       " u'Annual General Obligation Bonds Accountability (pdf)',\n",
       " u'10',\n",
       " u'01/01/14',\n",
       " u'Small Business Utilization (pdf)',\n",
       " u'11',\n",
       " u'01/01/14',\n",
       " u'Institutional Financial Aid Programs - Preliminary report (pdf)',\n",
       " u'12',\n",
       " u'01/10/14',\n",
       " u'Summer Enrollment (pdf)',\n",
       " u'13',\n",
       " u'01/15/14',\n",
       " u'Contracting Out for Services at Newly Developed Facilities (pdf)',\n",
       " u'14',\n",
       " u'03/01/14',\n",
       " u'Performance Measures (pdf)',\n",
       " u'15',\n",
       " u'03/01/14',\n",
       " u'Entry Level Writing Requirement (pdf)',\n",
       " u'16',\n",
       " u'03/31/14',\n",
       " u'Annual Report on Student\\xa0Financial Support (pdf)',\n",
       " u'17',\n",
       " u'04/01/14',\n",
       " u'Unique Statewide Pupil Identifier (pdf)',\n",
       " u'18',\n",
       " u'04/01/14',\n",
       " u'Riverside School of Medicine (pdf)',\n",
       " u'19',\n",
       " u'04/01/14',\n",
       " u'SAPEP Funds and Outcomes - N/A',\n",
       " u'20',\n",
       " u'05/15/14',\n",
       " u'Receipt and Use of Lottery Funds (pdf)',\n",
       " u'21',\n",
       " u'07/01/14',\n",
       " u'Cogeneration and Energy Consv Major Capital Projects (pdf)',\n",
       " u'\\n',\n",
       " u'\\n',\n",
       " u'\\n',\n",
       " u'\\xa0',\n",
       " u'Future Reports',\n",
       " u'\\n',\n",
       " u'24',\n",
       " u'12-',\n",
       " u'Breast Cancer Research Fund',\n",
       " u'25',\n",
       " u'12-31-15',\n",
       " u'Cigarette and Tobacco Products Surtax Research Program',\n",
       " u'26',\n",
       " u'01-01-16',\n",
       " u'Best Value Program',\n",
       " u'27',\n",
       " u'01-01-16',\n",
       " u'California Subject Matter Programs',\n",
       " u'28',\n",
       " u'04-01-16',\n",
       " u'COSMOS Program Outcomes']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll use a for loop to go through the list and grab only the cells with a pdf file in them, we'll also need to keep track of the index to set up the date of the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set up empty lists\n",
    "reports = []\n",
    "date = []\n",
    "\n",
    "# Se tindex counter\n",
    "index = 0\n",
    "\n",
    "# Go find the pdf cells\n",
    "for item in data:\n",
    "    if 'pdf' in item:\n",
    "        # Add the date and reports\n",
    "        date.append(data[index-1])\n",
    "        \n",
    "        # Get rid of \\xa0\n",
    "        reports.append(item.replace(u'\\xa0', u' '))\n",
    "                    \n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "You'll notice a line to take care of '\\xa0 ' This is due to a unicode error that occurs if you don't do this. Web pages can be messy and inconsistent and it is very likely you'll have to do some research to take care of problems like these.\n",
    "\n",
    "Here's the link I used to solve this particular issue: [StackOverflow Page](http://stackoverflow.com/questions/10993612/python-removing-xa0-from-string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now all that is left is to organize our data into a pandas DataFrame!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set up Dates and Reports as Series\n",
    "date = Series(date)\n",
    "reports = Series(reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Concatenate into a DataFrame\n",
    "legislative_df = pd.concat([date,reports],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set up the columns\n",
    "legislative_df.columns = ['Date','Reports']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Reports</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>08/01/13</td>\n",
       "      <td>2013-14 (EDU 92495) Proposed Capital Outlay Pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>09/01/13</td>\n",
       "      <td>2014-15  (EDU 92495) Proposed Capital Outlay P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11/01/13</td>\n",
       "      <td>Utilization of Classroom and Teaching Laborato...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11/01/13</td>\n",
       "      <td>Instruction and Research Space Summary &amp; Analy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11/15/13</td>\n",
       "      <td>Statewide Energy Partnership Program (pdf)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11/30/13</td>\n",
       "      <td>2013-23 Capital Financial Plan (pdf)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11/30/13</td>\n",
       "      <td>Projects Savings Funded from Capital Outlay Bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12/01/13</td>\n",
       "      <td>Streamlined Capital Projects Funded from Capit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>01/01/14</td>\n",
       "      <td>Annual General Obligation Bonds Accountability...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>01/01/14</td>\n",
       "      <td>Small Business Utilization (pdf)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>01/01/14</td>\n",
       "      <td>Institutional Financial Aid Programs - Prelimi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>01/10/14</td>\n",
       "      <td>Summer Enrollment (pdf)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>01/15/14</td>\n",
       "      <td>Contracting Out for Services at Newly Develope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>03/01/14</td>\n",
       "      <td>Performance Measures (pdf)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>03/01/14</td>\n",
       "      <td>Entry Level Writing Requirement (pdf)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>03/31/14</td>\n",
       "      <td>Annual Report on Student Financial Support (pdf)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>04/01/14</td>\n",
       "      <td>Unique Statewide Pupil Identifier (pdf)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>04/01/14</td>\n",
       "      <td>Riverside School of Medicine (pdf)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>05/15/14</td>\n",
       "      <td>Receipt and Use of Lottery Funds (pdf)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>07/01/14</td>\n",
       "      <td>Cogeneration and Energy Consv Major Capital Pr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date                                            Reports\n",
       "0   08/01/13  2013-14 (EDU 92495) Proposed Capital Outlay Pr...\n",
       "1   09/01/13  2014-15  (EDU 92495) Proposed Capital Outlay P...\n",
       "2   11/01/13  Utilization of Classroom and Teaching Laborato...\n",
       "3   11/01/13  Instruction and Research Space Summary & Analy...\n",
       "4   11/15/13         Statewide Energy Partnership Program (pdf)\n",
       "5   11/30/13               2013-23 Capital Financial Plan (pdf)\n",
       "6   11/30/13  Projects Savings Funded from Capital Outlay Bo...\n",
       "7   12/01/13  Streamlined Capital Projects Funded from Capit...\n",
       "8   01/01/14  Annual General Obligation Bonds Accountability...\n",
       "9   01/01/14                   Small Business Utilization (pdf)\n",
       "10  01/01/14  Institutional Financial Aid Programs - Prelimi...\n",
       "11  01/10/14                            Summer Enrollment (pdf)\n",
       "12  01/15/14  Contracting Out for Services at Newly Develope...\n",
       "13  03/01/14                         Performance Measures (pdf)\n",
       "14  03/01/14              Entry Level Writing Requirement (pdf)\n",
       "15  03/31/14   Annual Report on Student Financial Support (pdf)\n",
       "16  04/01/14            Unique Statewide Pupil Identifier (pdf)\n",
       "17  04/01/14                 Riverside School of Medicine (pdf)\n",
       "18  05/15/14             Receipt and Use of Lottery Funds (pdf)\n",
       "19  07/01/14  Cogeneration and Energy Consv Major Capital Pr..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the finished DataFrame\n",
    "legislative_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "There are other less intense options for web scraping:\n",
    "\n",
    "Check out these two companies:\n",
    "\n",
    "https://import.io/\n",
    "\n",
    "https://www.kimonolabs.com/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buyers:  ['Carson Busses', 'Earl E. Byrd', 'Patty Cakes', 'Derri Anne Connecticut', 'Moe Dess', 'Leda Doggslife', 'Dan Druff', 'Al Fresco', 'Ido Hoe', 'Howie Kisses', 'Len Lease', 'Phil Meup', 'Ira Pent', 'Ben D. Rules', 'Ave Sectomy', 'Gary Shattire', 'Bobbi Soks', 'Sheila Takya', 'Rose Tattoo', 'Moe Tell']\n",
      "Prices:  ['$29.95', '$8.37', '$15.26', '$19.25', '$19.25', '$13.99', '$31.57', '$8.49', '$14.47', '$15.86', '$11.11', '$15.98', '$16.27', '$7.50', '$50.85', '$14.26', '$5.68', '$15.00', '$114.07', '$10.09']\n"
     ]
    }
   ],
   "source": [
    "# http://docs.python-guide.org/en/latest/scenarios/scrape/\n",
    "\n",
    "from lxml import html\n",
    "import requests\n",
    "\n",
    "page = requests.get('http://econpy.pythonanywhere.com/ex/001.html')\n",
    "tree = html.fromstring(page.content)\n",
    "\n",
    "# inspect element\n",
    "# <div title=\"buyer-name\">Carson Busses</div>\n",
    "# <span class=\"item-price\">$29.95</span>\n",
    "\n",
    "#This will create a list of buyers:\n",
    "buyers = tree.xpath('//div[@title=\"buyer-name\"]/text()')\n",
    "#This will create a list of prices\n",
    "prices = tree.xpath('//span[@class=\"item-price\"]/text()')\n",
    "\n",
    "print 'Buyers: ', buyers\n",
    "print 'Prices: ', prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# https://www.flightradar24.com/56.16,-52.58/7\n",
    "# http://stackoverflow.com/questions/39489168/how-to-scrape-real-time-streaming-data-with-python\n",
    "\n",
    "# If you look at the network tab in the developer console in Chrome (for example), you'll see the requests to https://data-live.flightradar24.com/zones/fcgi/feed.js?bounds=59.09,52.64,-58.77,-47.71&faa=1&mlat=1&flarm=1&adsb=1&gnd=1&air=1&vehicles=1&estimated=1&maxage=7200&gliders=1&stats=1\n",
    "\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "def get_count():\n",
    "    url = \"https://data-live.flightradar24.com/zones/fcgi/feed.js?bounds=57.78,54.11,-56.40,-48.75&faa=1&mlat=1&flarm=1&adsb=1&gnd=1&air=1&vehicles=1&estimated=1&maxage=7200&gliders=1&stats=1\"\n",
    "    \n",
    "    # Request with fake header, otherwise you will get an 403 HTTP error\n",
    "    r = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "    \n",
    "    # Parse the JSON\n",
    "    data = r.json()\n",
    "    counter = 0\n",
    "    \n",
    "    # Iterate over the elements to get the number of total flights\n",
    "    for element in data[\"stats\"][\"total\"]:\n",
    "        counter += data[\"stats\"][\"total\"][element]\n",
    "    \n",
    "    return counter\n",
    "\n",
    "while True:\n",
    "    print(get_count())\n",
    "    time.sleep(8)\n",
    "\n",
    "# Hmm, that was just my first thaught. As I wrote, the code is not meant as something final \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Good Job!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
